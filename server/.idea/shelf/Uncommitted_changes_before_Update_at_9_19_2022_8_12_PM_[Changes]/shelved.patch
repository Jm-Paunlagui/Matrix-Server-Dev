Index: controllers/prediction.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from decimal import Decimal\r\n\r\nfrom config.app import app\r\nimport mysql.connector\r\nfrom flask import jsonify, request\r\nfrom datetime import datetime\r\nfrom keras.utils import pad_sequences\r\nimport pickle\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom keras.models import load_model\r\n\r\nconnect_to_matrix = mysql.connector.connect(host=\"localhost\", user=\"root\", password=\"\", database=\"production_saer\")\r\nmatrix_cursor = connect_to_matrix.cursor(buffered=True)\r\n\r\n# @desc: Get all the tables and columns from a database\r\n# @app.route('/tables-columns', methods=['POST'])\r\n# def tables_columns():\r\n#     if request.is_json:\r\n#         host = request.json['host']\r\n#         user = request.json['user']\r\n#         password = request.json['password']\r\n#         database = request.json['database']\r\n#\r\n#         try:\r\n#             conn = mysql.connector.connect(host=host, user=user, password=password, database=database)\r\n#             cursor = conn.cursor()\r\n#             cursor.execute(\"SHOW TABLES\")\r\n#             tables = cursor.fetchall()\r\n#             tables_columns = []\r\n#             for table in tables:\r\n#                 cursor.execute(\"SHOW COLUMNS FROM {}\".format(table[0]))\r\n#                 columns = cursor.fetchall()\r\n#                 # table and column name only\r\n#                 tables_columns.append({'table': table[0], 'columns': [column[0] for column in columns]})\r\n#             return jsonify(\r\n#                 {'status': 'success', 'message': 'Tables and columns found', 'tables_columns': tables_columns})\r\n#         except mysql.connector.Error as err:\r\n#             return jsonify({'status': 'error', 'message': 'Connection failed: {}'.format(err)})\r\n#     else:\r\n#         return jsonify({'status': 'error', 'message': 'Invalid request'})\r\n\r\n\r\n# @desc: Get all the data from a table\r\n# @app.route('/data', methods=['POST'])\r\n# def data():\r\n#     if request.is_json:\r\n#         host = request.json['host']\r\n#         user = request.json['user']\r\n#         password = request.json['password']\r\n#         database = request.json['database']\r\n#         table = request.json['table']\r\n#\r\n#         try:\r\n#             conn = mysql.connector.connect(host=host, user=user, password=password, database=database)\r\n#             cursor = conn.cursor()\r\n#             cursor.execute(\"SELECT * FROM {}\".format(table))\r\n#             data = cursor.fetchall()\r\n#             return jsonify({'status': 'success', 'message': 'Data found', 'data': data})\r\n#         except mysql.connector.Error as err:\r\n#             return jsonify({'status': 'error', 'message': 'Connection failed: {}'.format(err)})\r\n#     else:\r\n#         return jsonify({'status': 'error', 'message': 'Invalid request'})\r\n\r\n\r\nmodel = load_model(\"config/model.h5\")\r\ntokenizer = pickle.load(open(\"config/tokenizer.pickle\", \"rb\"))\r\n\r\n\r\n# @desc: Predict the sentiment of a text and return the result to the database with a new column containing the\r\n# sentiment, professor name, sentence, and date\r\n@app.route('/analyze_sentiment_from_db', methods=['POST'])\r\ndef analyze_sentiment_from_db():\r\n    # Connect to the database\r\n    if request.is_json:\r\n        host = request.json['host']  # Required\r\n        user = request.json['user']  # Required\r\n        password = request.json['password']  # Required\r\n        database = request.json['database']  # Required\r\n        table = request.json['table']  # Required\r\n        input_source = request.json['input_source']  # Required\r\n        evaluatee = request.json['evaluatee']  # Required\r\n        evaluatee_dept = request.json['evaluatee_dept']  # Required\r\n        course_code = request.json['course_code']  # Required\r\n        input_data_id = request.json['input_data_id']  # Required\r\n\r\n        school_year_and_semester = request.json['school_year_and_semester']  # Required\r\n\r\n        # Type confirm to confirm the prediction and save it to the database\r\n        type_confirm = request.json['type_confirm']\r\n\r\n        if type_confirm == input_source:\r\n            try:\r\n                conn = mysql.connector.connect(host=host, user=user, password=password, database=database)\r\n                cursor = conn.cursor()\r\n                cursor.execute(\"SELECT %s FROM %s\" % (input_source, table))\r\n                data = cursor.fetchall()\r\n\r\n                cursor.execute(\"SELECT %s, %s, %s, %s FROM %s\" %\r\n                               (evaluatee, evaluatee_dept, course_code, input_data_id, table))\r\n                info = cursor.fetchall()\r\n\r\n                infor_evaluatee = [x[0] for x in info]\r\n                infor_evaluatee_dept = [x[1] for x in info]\r\n                infor_course_code = [x[2] for x in info]\r\n                infor_input_data_id = [x[3] for x in info]\r\n                data = [x[0] for x in data]\r\n                raw = [x[0] for x in data]\r\n\r\n                # @desc: if the data is NoneType, then it will be replaced with\r\n                # an empty string to avoid errors when lower casing the data\r\n                for i in enumerate(data):\r\n                    if i[1] is None:\r\n                        data[i[0]] = \"\"\r\n                    else:\r\n                        data[i[0]] = i[1].lower()\r\n\r\n                # @desc: Tokenize the data\r\n                data = tokenizer.texts_to_sequences(data)\r\n                # @desc: Convert the text to sequences\r\n                data = pad_sequences(data, padding='post', maxlen=300)\r\n\r\n                # @desc: Predict the sentiment of the data\r\n                # @desc: Convert the sentiment to a string\r\n                # @desc: Save the sentiment to the database\r\n                predictions = model.predict(data)\r\n                predictions = predictions.tolist()\r\n                # Limit the number of decimal places to 4\r\n                predictions = [round(x[0], 2) * 100 for x in predictions]\r\n                now = datetime.now()\r\n                analyzed = now.strftime(\"%A %d %B, %Y at %I:%M:%S %p\")\r\n\r\n                # Add the sentiment to the database with the following columns\r\n                # (evaluatee, evaluatee_dept, course_code, input_data_id,\r\n                # sentiment, analyzed) and the sentiment will be saved\r\n                # to the database\r\n                for i in enumerate(predictions):\r\n                    matrix_cursor.executemany(\r\n                        \"INSERT INTO 21_predicted_data \"\r\n                        \"(`input_source`, `evaluatee`, `evaluatee_dept`, `course_code`, `input_data_id`, \"\r\n                        \"`input_data`, `input_sentiment`, `is_predicted`, `date_analyzed`, \"\r\n                        \"`school_year_and_semester`) \"\r\n                        \"VALUES ('{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}')\".format(\r\n                            input_source, infor_evaluatee[i[0]], infor_evaluatee_dept[i[0]], infor_course_code[i[0]],\r\n                            infor_input_data_id[i[0]], raw[i[0]], predictions[i[0]], 1, analyzed,\r\n                            school_year_and_semester), multi=True)\r\n\r\n                connect_to_matrix.commit()\r\n                return jsonify(\r\n                    {'status': 'success', 'message': 'Data source analyzed and saved',\r\n                     'column_selected': input_source, })\r\n            except mysql.connector.Error as err:\r\n                return jsonify({'status': 'error', 'message': 'Connection failed: {}'.format(err)})\r\n    else:\r\n        return jsonify({'status': 'error', 'message': 'Invalid request'})\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/controllers/prediction.py b/controllers/prediction.py
--- a/controllers/prediction.py	(revision f24ef6a4722b76554e8405fb9d62246409cb9ab3)
+++ b/controllers/prediction.py	(date 1663589548122)
@@ -94,11 +94,11 @@
             try:
                 conn = mysql.connector.connect(host=host, user=user, password=password, database=database)
                 cursor = conn.cursor()
-                cursor.execute("SELECT %s FROM %s" % (input_source, table))
+                cursor.execute("SELECT %s FROM %s where %s IS NOT NULL " % (input_source, table, input_source))
                 data = cursor.fetchall()
 
-                cursor.execute("SELECT %s, %s, %s, %s FROM %s" %
-                               (evaluatee, evaluatee_dept, course_code, input_data_id, table))
+                cursor.execute("SELECT %s, %s, %s, %s FROM %s WHERE %s IS NOT NULL" %
+                               (evaluatee, evaluatee_dept, course_code, input_data_id, table, input_source))
                 info = cursor.fetchall()
 
                 infor_evaluatee = [x[0] for x in info]
@@ -106,47 +106,65 @@
                 infor_course_code = [x[2] for x in info]
                 infor_input_data_id = [x[3] for x in info]
                 data = [x[0] for x in data]
-                raw = [x[0] for x in data]
 
-                # @desc: if the data is NoneType, then it will be replaced with
-                # an empty string to avoid errors when lower casing the data
-                for i in enumerate(data):
-                    if i[1] is None:
-                        data[i[0]] = ""
-                    else:
-                        data[i[0]] = i[1].lower()
+                # @desc: Clean the text by removing white
+                # spaces, tabs, and new lines using regex
+                def clean_text(text):
+                    text = text.lower()
+                    text = text.strip()
+                    text = text.replace("\n", "")
+                    text = text.replace("\t", "")
+                    text = text.replace("\r", "")
+                    return text
 
-                # @desc: Tokenize the data
-                data = tokenizer.texts_to_sequences(data)
-                # @desc: Convert the text to sequences
-                data = pad_sequences(data, padding='post', maxlen=300)
+                # @desc: Clean the text
+                data = [clean_text(text) for text in data]
 
-                # @desc: Predict the sentiment of the data
-                # @desc: Convert the sentiment to a string
-                # @desc: Save the sentiment to the database
-                predictions = model.predict(data)
-                predictions = predictions.tolist()
-                # Limit the number of decimal places to 4
-                predictions = [round(x[0], 2) * 100 for x in predictions]
-                now = datetime.now()
-                analyzed = now.strftime("%A %d %B, %Y at %I:%M:%S %p")
+                # @desc: Write the data to a csv file
+                with open('data.csv', 'w', encoding='utf-8') as f:
+                    f.write("text) \n")  # header
+                    for text in data:
+                        f.write(text + " \n")
 
-                # Add the sentiment to the database with the following columns
-                # (evaluatee, evaluatee_dept, course_code, input_data_id,
-                # sentiment, analyzed) and the sentiment will be saved
-                # to the database
-                for i in enumerate(predictions):
-                    matrix_cursor.executemany(
-                        "INSERT INTO 21_predicted_data "
-                        "(`input_source`, `evaluatee`, `evaluatee_dept`, `course_code`, `input_data_id`, "
-                        "`input_data`, `input_sentiment`, `is_predicted`, `date_analyzed`, "
-                        "`school_year_and_semester`) "
-                        "VALUES ('{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}')".format(
-                            input_source, infor_evaluatee[i[0]], infor_evaluatee_dept[i[0]], infor_course_code[i[0]],
-                            infor_input_data_id[i[0]], raw[i[0]], predictions[i[0]], 1, analyzed,
-                            school_year_and_semester), multi=True)
+                # @desc: A function that will exempt the punctuation and
+                # apostrophe from the text to save it to the database
 
-                connect_to_matrix.commit()
+                # raw = data
+                #
+                # # @desc: Convert the text to lowercase
+                # data = [x.lower() for x in data]
+                #
+                # # @desc: Tokenize the data
+                # data = tokenizer.texts_to_sequences(data)
+                # # @desc: Convert the text to sequences
+                # data = pad_sequences(data, padding='post', maxlen=300)
+                #
+                # # @desc: Predict the sentiment of the data
+                # # @desc: Convert the sentiment to a string
+                # # @desc: Save the sentiment to the database
+                # predictions = model.predict(data)
+                # predictions = predictions.tolist()
+                # # Limit the number of decimal places to 4
+                # predictions = [round(x[0], 2) * 100 for x in predictions]
+                # now = datetime.now()
+                # analyzed = now.strftime("%A %d %B, %Y at %I:%M:%S %p")
+                #
+                # # Add the sentiment to the database with the following columns
+                # # (evaluatee, evaluatee_dept, course_code, input_data_id,
+                # # sentiment, analyzed) and the sentiment will be saved
+                # # to the database
+                # for i in enumerate(predictions):
+                #     matrix_cursor.execute(
+                #         "INSERT INTO 21_predicted_data "
+                #         "(`input_source`, `evaluatee`, `evaluatee_dept`, `course_code`, `input_data_id`, "
+                #         "`input_data`, `input_sentiment`, `is_predicted`, `date_analyzed`, "
+                #         "`school_year_and_semester`) "
+                #         "VALUES ('{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}')".format(
+                #             input_source, infor_evaluatee[i[0]], infor_evaluatee_dept[i[0]], infor_course_code[i[0]],
+                #             infor_input_data_id[i[0]], raw[i[0]], predictions[i[0]], 1, analyzed,
+                #             school_year_and_semester))
+                #
+                # connect_to_matrix.commit()
                 return jsonify(
                     {'status': 'success', 'message': 'Data source analyzed and saved',
                      'column_selected': input_source, })
